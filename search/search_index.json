{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Prefect Fugue Integration This project provides the Fugue tasks, context and blocks for Prefect. Getting Started Python setup Requires an installation of Python 3.7+. We recommend using a Python virtual environment manager such as pipenv, conda or virtualenv. These tasks are designed to work with Prefect 2.0. For more information about how to use Prefect, please refer to the Prefect documentation . Installation Install prefect-fugue with pip : pip install prefect-fugue It's also recommended to register Fugue blocks into your current Prefect workspace: prefect block register -m prefect_fugue Hello World from prefect import flow from prefect_fugue import fugue_engine , fsql @flow def hello_flow (): fsql ( \"\"\" CREATE [[0]] SCHEMA a:int PRINT \"\"\" ) hello_flow () @flow def world_flow ( n , engine ): with fugue_engine ( engine ): fsql ( \"\"\" CREATE [[0],[1]] SCHEMA a:int SELECT * WHERE a>0 PRINT \"\"\" , n = n ) world_flow ( 1 , \"duckdb\" ) # running using duckdb (assuming duckdb is installed) world_flow ( 2 , \"fugue/my_databricks\" ) # running using my_databricks block on Prefect Resources If you encounter any bugs while using prefect-fugue , feel free to open an issue in the prefect-fugue repository. If you have any questions or issues while using prefect-fugue , you can find help in either the Prefect Discourse forum or the Prefect Slack community . Development If you'd like to install a version of prefect-fugue for development, clone the repository and perform an editable install with pip : git clone https://github.com/fugue-project/prefect-fugue.git cd prefect-fugue/ pip install -e \".[dev]\" # Install linting pre-commit hooks pre-commit install","title":"Home"},{"location":"#prefect-fugue-integration","text":"This project provides the Fugue tasks, context and blocks for Prefect.","title":"Prefect Fugue Integration"},{"location":"#getting-started","text":"","title":"Getting Started"},{"location":"#python-setup","text":"Requires an installation of Python 3.7+. We recommend using a Python virtual environment manager such as pipenv, conda or virtualenv. These tasks are designed to work with Prefect 2.0. For more information about how to use Prefect, please refer to the Prefect documentation .","title":"Python setup"},{"location":"#installation","text":"Install prefect-fugue with pip : pip install prefect-fugue It's also recommended to register Fugue blocks into your current Prefect workspace: prefect block register -m prefect_fugue","title":"Installation"},{"location":"#hello-world","text":"from prefect import flow from prefect_fugue import fugue_engine , fsql @flow def hello_flow (): fsql ( \"\"\" CREATE [[0]] SCHEMA a:int PRINT \"\"\" ) hello_flow () @flow def world_flow ( n , engine ): with fugue_engine ( engine ): fsql ( \"\"\" CREATE [[0],[1]] SCHEMA a:int SELECT * WHERE a>0 PRINT \"\"\" , n = n ) world_flow ( 1 , \"duckdb\" ) # running using duckdb (assuming duckdb is installed) world_flow ( 2 , \"fugue/my_databricks\" ) # running using my_databricks block on Prefect","title":"Hello World"},{"location":"#resources","text":"If you encounter any bugs while using prefect-fugue , feel free to open an issue in the prefect-fugue repository. If you have any questions or issues while using prefect-fugue , you can find help in either the Prefect Discourse forum or the Prefect Slack community .","title":"Resources"},{"location":"#development","text":"If you'd like to install a version of prefect-fugue for development, clone the repository and perform an editable install with pip : git clone https://github.com/fugue-project/prefect-fugue.git cd prefect-fugue/ pip install -e \".[dev]\" # Install linting pre-commit hooks pre-commit install","title":"Development"},{"location":"blocks/","text":"prefect_fugue.blocks FugueEngine FugueEngine contains Fugue ExecutionEngine name, configs and secret configs. Available names depends on what Fugue plugins have been installed. Parameters: Name Type Description Default - engine Fugue ExecutionEngine name required - engine_conf Fugue ExecutionEngine config required - secret_conf Fugue ExecutionEngine config that should be encoded. For example the token for accessing Databricks. required Note It is not recommented to directly use this Block. Instead, you should use the full block expression fugue/<block_name> as the engine name in :func: prefect_fugue.context.fugue_engine Source code in prefect_fugue/blocks.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 class FugueEngine ( Block ): \"\"\" FugueEngine contains Fugue ExecutionEngine name, configs and secret configs. Available names depends on what Fugue plugins have been installed. Args: - engine: Fugue ExecutionEngine name - engine_conf: Fugue ExecutionEngine config - secret_conf: Fugue ExecutionEngine config that should be encoded. For example the token for accessing Databricks. Note: It is not recommented to directly use this Block. Instead, you should use the full block expression `fugue/<block_name>` as the engine name in :func:`prefect_fugue.context.fugue_engine` \"\"\" _block_type_name = \"Fugue Engine\" _block_type_slug = \"fugue\" _logo_url = \"https://avatars.githubusercontent.com/u/65140352?s=200&v=4\" # noqa _description = \"Configs that can consturct a Fugue Execution Engine\" engine : str = Field ( ... , alias = \"engine_name\" ) conf : Optional [ Dict [ str , Any ]] = Field ( default = None , alias = \"engine_config\" , description = \"A JSON-dict-compatible value\" , ) secret_conf : Optional [ Dict [ str , SecretStr ]] = Field ( default = None , alias = \"secret_config\" , description = \"A JSON-dict-compatible value\" , ) def make_engine ( self , custom_conf : Any = None ) -> ExecutionEngine : conf = ParamDict ( self . conf ) if self . secret_conf is not None : for k , v in self . secret_conf . items (): conf [ k ] = v . get_secret_value () conf . update ( ParamDict ( custom_conf )) return make_execution_engine ( self . engine , conf )","title":"Blocks"},{"location":"blocks/#prefect_fugue.blocks","text":"","title":"blocks"},{"location":"blocks/#prefect_fugue.blocks.FugueEngine","text":"FugueEngine contains Fugue ExecutionEngine name, configs and secret configs. Available names depends on what Fugue plugins have been installed. Parameters: Name Type Description Default - engine Fugue ExecutionEngine name required - engine_conf Fugue ExecutionEngine config required - secret_conf Fugue ExecutionEngine config that should be encoded. For example the token for accessing Databricks. required Note It is not recommented to directly use this Block. Instead, you should use the full block expression fugue/<block_name> as the engine name in :func: prefect_fugue.context.fugue_engine Source code in prefect_fugue/blocks.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 class FugueEngine ( Block ): \"\"\" FugueEngine contains Fugue ExecutionEngine name, configs and secret configs. Available names depends on what Fugue plugins have been installed. Args: - engine: Fugue ExecutionEngine name - engine_conf: Fugue ExecutionEngine config - secret_conf: Fugue ExecutionEngine config that should be encoded. For example the token for accessing Databricks. Note: It is not recommented to directly use this Block. Instead, you should use the full block expression `fugue/<block_name>` as the engine name in :func:`prefect_fugue.context.fugue_engine` \"\"\" _block_type_name = \"Fugue Engine\" _block_type_slug = \"fugue\" _logo_url = \"https://avatars.githubusercontent.com/u/65140352?s=200&v=4\" # noqa _description = \"Configs that can consturct a Fugue Execution Engine\" engine : str = Field ( ... , alias = \"engine_name\" ) conf : Optional [ Dict [ str , Any ]] = Field ( default = None , alias = \"engine_config\" , description = \"A JSON-dict-compatible value\" , ) secret_conf : Optional [ Dict [ str , SecretStr ]] = Field ( default = None , alias = \"secret_config\" , description = \"A JSON-dict-compatible value\" , ) def make_engine ( self , custom_conf : Any = None ) -> ExecutionEngine : conf = ParamDict ( self . conf ) if self . secret_conf is not None : for k , v in self . secret_conf . items (): conf [ k ] = v . get_secret_value () conf . update ( ParamDict ( custom_conf )) return make_execution_engine ( self . engine , conf )","title":"FugueEngine"},{"location":"context/","text":"prefect_fugue.context FugueEngineContext The context for Fugue ExecutionEngine. Attributes: Name Type Description engines List [ ExecutionEngine ] A stack of Fugue ExecutionEngines Source code in prefect_fugue/context.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class FugueEngineContext ( ContextModel ): \"\"\" The context for Fugue ExecutionEngine. Attributes: engines: A stack of Fugue ExecutionEngines \"\"\" engines : List [ ExecutionEngine ] = [] @classmethod def get ( cls ) -> \"FugueEngineContext\" : # Return an empty `FugueEngineContext` instead of `None` if no context exists return cls . __var__ . get ( FugueEngineContext ()) def __exit__ ( self , * _ ): try : if len ( self . engines ) > 0 : self . engines . pop () . _prefect_context_stop () finally : super () . __exit__ ( * _ ) __var__ = ContextVar ( \"fugue_engine\" ) current_fugue_engine Get the current Fugue ExecutionEngine created by the latest context manager Returns: Type Description Optional [ ExecutionEngine ] ExecutionEngine, optional: if within a context, then the latest Fugue Optional [ ExecutionEngine ] ExecutionEngine created by fugue_engine , else None. Source code in prefect_fugue/context.py 33 34 35 36 37 38 39 40 41 42 43 def current_fugue_engine () -> Optional [ ExecutionEngine ]: \"\"\" Get the current Fugue ExecutionEngine created by the latest context manager Returns: ExecutionEngine, optional: if within a context, then the latest Fugue ExecutionEngine created by ``fugue_engine``, else None. \"\"\" engines = FugueEngineContext . get () . engines return None if len ( engines ) == 0 else engines [ - 1 ] fugue_engine Context manager to create a new Fugue Execution Engine. Parameters: Name Type Description Default - engine (object the object that can be converted to a Fugue ExecutionEngine . required - conf (object the object that can be converted to a dict of Fugue configs. required - checkpoint (bool for the steps using this engine, whether to enable checkpoint, defaults to False. required Yields: Type Description ExecutionEngine The current Fugue Execution Engine Examples: from prefect import flow from prefect_fugue import fugue_engine , fsql @flow def my_flow (): with fugue_engine ( \"duckdb\" ): res = fsql ( \"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\" ) fsql ( \"PRINT x\" , res ) my_flow () @flow def flexible_flow ( engine ): with fugue_engine ( engine , { \"some_config\" : \"hello\" }): res = fsql ( \"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\" ) fsql ( \"PRINT x\" , res ) flexible_flow ( \"duckdb\" ) # using DuckDB backend flexible_flow ( \"fugue/my_engine_conf\" ) # using a FugueEngine block Source code in prefect_fugue/context.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 @contextmanager def fugue_engine ( engine : Any = None , conf : Any = None , checkpoint : bool = False , ) -> ExecutionEngine : \"\"\" Context manager to create a new Fugue Execution Engine. Args: - engine (object, optional): the object that can be converted to a Fugue ``ExecutionEngine``. - conf (object, optional): the object that can be converted to a dict of Fugue configs. - checkpoint (bool): for the steps using this engine, whether to enable checkpoint, defaults to False. Yields: The current Fugue Execution Engine Examples: ```python from prefect import flow from prefect_fugue import fugue_engine, fsql @flow def my_flow(): with fugue_engine(\"duckdb\"): res = fsql(\"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\") fsql(\"PRINT x\", res) my_flow() @flow def flexible_flow(engine): with fugue_engine(engine, {\"some_config\":\"hello\"}): res = fsql(\"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\") fsql(\"PRINT x\", res) flexible_flow(\"duckdb\") # using DuckDB backend flexible_flow(\"fugue/my_engine_conf\") # using a FugueEngine block ``` \"\"\" engines = FugueEngineContext . get () . engines new_engine = make_execution_engine ( engine , conf = conf ) new_engine . _prefect_context_stop = new_engine . stop new_engine . stop = _no_op_stop new_engine . _prefect_default_checkpoint = checkpoint with FugueEngineContext ( engines = list ( engines ) + [ new_engine ]): yield new_engine get_current_checkpoint Get the current checkpoint setting Parameters: Name Type Description Default - checkpoint (bool get the checkpoint setting, defaults to None. required Returns: Name Type Description bool bool if checkpoint is not None then the value itself, else if it is in bool a fugue_engine context manager, then return the checkpoint setting of the bool current engine, else False. Source code in prefect_fugue/context.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def get_current_checkpoint ( checkpoint : Optional [ bool ] = None , ) -> bool : \"\"\" Get the current checkpoint setting Args: - checkpoint (bool, optional): get the checkpoint setting, defaults to None. Returns: bool: if ``checkpoint`` is not None then the value itself, else if it is in a ``fugue_engine`` context manager, then return the checkpoint setting of the current engine, else False. \"\"\" if checkpoint is not None : return checkpoint current_engine = current_fugue_engine () if current_engine is not None : return current_engine . _prefect_default_checkpoint return False","title":"Context"},{"location":"context/#prefect_fugue.context","text":"","title":"context"},{"location":"context/#prefect_fugue.context.FugueEngineContext","text":"The context for Fugue ExecutionEngine. Attributes: Name Type Description engines List [ ExecutionEngine ] A stack of Fugue ExecutionEngines Source code in prefect_fugue/context.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class FugueEngineContext ( ContextModel ): \"\"\" The context for Fugue ExecutionEngine. Attributes: engines: A stack of Fugue ExecutionEngines \"\"\" engines : List [ ExecutionEngine ] = [] @classmethod def get ( cls ) -> \"FugueEngineContext\" : # Return an empty `FugueEngineContext` instead of `None` if no context exists return cls . __var__ . get ( FugueEngineContext ()) def __exit__ ( self , * _ ): try : if len ( self . engines ) > 0 : self . engines . pop () . _prefect_context_stop () finally : super () . __exit__ ( * _ ) __var__ = ContextVar ( \"fugue_engine\" )","title":"FugueEngineContext"},{"location":"context/#prefect_fugue.context.current_fugue_engine","text":"Get the current Fugue ExecutionEngine created by the latest context manager Returns: Type Description Optional [ ExecutionEngine ] ExecutionEngine, optional: if within a context, then the latest Fugue Optional [ ExecutionEngine ] ExecutionEngine created by fugue_engine , else None. Source code in prefect_fugue/context.py 33 34 35 36 37 38 39 40 41 42 43 def current_fugue_engine () -> Optional [ ExecutionEngine ]: \"\"\" Get the current Fugue ExecutionEngine created by the latest context manager Returns: ExecutionEngine, optional: if within a context, then the latest Fugue ExecutionEngine created by ``fugue_engine``, else None. \"\"\" engines = FugueEngineContext . get () . engines return None if len ( engines ) == 0 else engines [ - 1 ]","title":"current_fugue_engine()"},{"location":"context/#prefect_fugue.context.fugue_engine","text":"Context manager to create a new Fugue Execution Engine. Parameters: Name Type Description Default - engine (object the object that can be converted to a Fugue ExecutionEngine . required - conf (object the object that can be converted to a dict of Fugue configs. required - checkpoint (bool for the steps using this engine, whether to enable checkpoint, defaults to False. required Yields: Type Description ExecutionEngine The current Fugue Execution Engine Examples: from prefect import flow from prefect_fugue import fugue_engine , fsql @flow def my_flow (): with fugue_engine ( \"duckdb\" ): res = fsql ( \"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\" ) fsql ( \"PRINT x\" , res ) my_flow () @flow def flexible_flow ( engine ): with fugue_engine ( engine , { \"some_config\" : \"hello\" }): res = fsql ( \"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\" ) fsql ( \"PRINT x\" , res ) flexible_flow ( \"duckdb\" ) # using DuckDB backend flexible_flow ( \"fugue/my_engine_conf\" ) # using a FugueEngine block Source code in prefect_fugue/context.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 @contextmanager def fugue_engine ( engine : Any = None , conf : Any = None , checkpoint : bool = False , ) -> ExecutionEngine : \"\"\" Context manager to create a new Fugue Execution Engine. Args: - engine (object, optional): the object that can be converted to a Fugue ``ExecutionEngine``. - conf (object, optional): the object that can be converted to a dict of Fugue configs. - checkpoint (bool): for the steps using this engine, whether to enable checkpoint, defaults to False. Yields: The current Fugue Execution Engine Examples: ```python from prefect import flow from prefect_fugue import fugue_engine, fsql @flow def my_flow(): with fugue_engine(\"duckdb\"): res = fsql(\"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\") fsql(\"PRINT x\", res) my_flow() @flow def flexible_flow(engine): with fugue_engine(engine, {\"some_config\":\"hello\"}): res = fsql(\"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\") fsql(\"PRINT x\", res) flexible_flow(\"duckdb\") # using DuckDB backend flexible_flow(\"fugue/my_engine_conf\") # using a FugueEngine block ``` \"\"\" engines = FugueEngineContext . get () . engines new_engine = make_execution_engine ( engine , conf = conf ) new_engine . _prefect_context_stop = new_engine . stop new_engine . stop = _no_op_stop new_engine . _prefect_default_checkpoint = checkpoint with FugueEngineContext ( engines = list ( engines ) + [ new_engine ]): yield new_engine","title":"fugue_engine()"},{"location":"context/#prefect_fugue.context.get_current_checkpoint","text":"Get the current checkpoint setting Parameters: Name Type Description Default - checkpoint (bool get the checkpoint setting, defaults to None. required Returns: Name Type Description bool bool if checkpoint is not None then the value itself, else if it is in bool a fugue_engine context manager, then return the checkpoint setting of the bool current engine, else False. Source code in prefect_fugue/context.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def get_current_checkpoint ( checkpoint : Optional [ bool ] = None , ) -> bool : \"\"\" Get the current checkpoint setting Args: - checkpoint (bool, optional): get the checkpoint setting, defaults to None. Returns: bool: if ``checkpoint`` is not None then the value itself, else if it is in a ``fugue_engine`` context manager, then return the checkpoint setting of the current engine, else False. \"\"\" if checkpoint is not None : return checkpoint current_engine = current_fugue_engine () if current_engine is not None : return current_engine . _prefect_default_checkpoint return False","title":"get_current_checkpoint()"},{"location":"tasks/","text":"prefect_fugue.tasks fsql Function for running Fugue SQL. This function generates the Prefect task that runs Fugue SQL. Parameters: Name Type Description Default - query (str the Fugue SQL query required - yields (Any the yielded dataframes from the previous tasks, defaults to None. It can be a single yielded result or an array of yielded results (see example) required - engine (Any execution engine expression that can be recognized by Fugue, default to None (the default ExecutionEngine of Fugue) required - engine_conf (Any extra execution engine configs, defaults to None required - checkpoint (bool whether to checkpoint this task in Prefect, defaults to None (determined by the fugue_engine context). required - **kwargs (Any additional kwargs to pass to Fugue's fsql function required References See: Fugue SQL Tutorial Example from prefect import flow , task from prefect.tasks.fugue import fsql , fugue_engine import pandas as pd # Basic usage @flow def flow1 () res1 = fsql ( \"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\" ) res2 = fsql ( \"CREATE [[1],[2]] SCHEMA a:int YIELD DATAFRAME AS y\" ) fsql ( ''' SELECT * FROM x UNION SELECT * FROM y SELECT * WHERE a<2 PRINT ''' , [ res1 , res2 ]) # SQL union using pandas fsql ( ''' SELECT * FROM x UNION SELECT * FROM y SELECT * WHERE a<2 PRINT ''' , [ res1 , res2 ], engine = \"duckdb\" ) # SQL union using duckdb (if installed) # Pass in other parameters and dataframes @task def gen_df (): return pd . DataFrame ( dict ( a = [ 1 ])) @task def gen_path (): return \"/tmp/t.parquet\" @flow def flow2 () df = gen_df () path = gen_path () fsql ( ''' SELECT a+1 AS a FROM df SAVE OVERWRITE {{path}} ''' , df = df , path = path ) # Disable checkpoint for distributed dataframes from pyspark.sql import SparkSession spark = SparkSession . builder . getOrCreate () @flow def flow3 () with fugue_engine ( spark , checkpoint = False ): # res1 needs to turn off checkpoint because it yields # a Spark DataFrame res1 = fsql ( ''' CREATE [[1],[2]] SCHEMA a:int YIELD DATAFRAME AS y ''' ) # res2 doesn't need to turn off checkpoint because it yields # a local DataFrame (most likely Pandas DataFrame) res2 = fsql ( ''' CREATE [[1],[2]] SCHEMA a:int YIELD LOCAL DATAFRAME AS y ''' , checkpoint = True ) # res3 doesn't need to turn off checkpoint because it yields # a file (the dataframe is cached in the file) res3 = fsql ( ''' CREATE [[-1],[3]] SCHEMA a:int YIELD FILE AS z ''' , checkpoint = True ) # this step doesn't need to turn off checkpoint because it # doesn't have any output fsql ( ''' SELECT * FROM x UNION SELECT * FROM y UNION SELECT * FROM z SELECT * WHERE a<2 PRINT ''' , [ res1 , res2 , res3 ]) you want to yield a distributed dataframe such as Spark or Dask, think it twice. YIELD FILE is always preferred when Fugue SQL is running as a Prefect task. If you feel YIELD FILE is too heavy, that means your SQL logic may not be heavy enough to be broken into multiple tasks. Source code in prefect_fugue/tasks.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def fsql ( query : str , yields : Any = None , engine : Any = None , engine_conf : Any = None , checkpoint : Optional [ bool ] = None , fsql_ignore_case : bool = False , ** kwargs : Any ) -> dict : \"\"\" Function for running Fugue SQL. This function generates the Prefect task that runs Fugue SQL. Args: - query (str): the Fugue SQL query - yields (Any): the yielded dataframes from the previous tasks, defaults to None. It can be a single yielded result or an array of yielded results (see example) - engine (Any): execution engine expression that can be recognized by Fugue, default to None (the default ExecutionEngine of Fugue) - engine_conf (Any): extra execution engine configs, defaults to None - checkpoint (bool, optional): whether to checkpoint this task in Prefect, defaults to None (determined by the ``fugue_engine`` context). - **kwargs (Any, optional): additional kwargs to pass to Fugue's `fsql` function References: - See: [Fugue SQL Tutorial](https://fugue-tutorials.readthedocs.io/tutorials/fugue_sql/index.html) Example: ```python from prefect import flow, task from prefect.tasks.fugue import fsql, fugue_engine import pandas as pd # Basic usage @flow def flow1() res1 = fsql(\"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\") res2 = fsql(\"CREATE [[1],[2]] SCHEMA a:int YIELD DATAFRAME AS y\") fsql(''' SELECT * FROM x UNION SELECT * FROM y SELECT * WHERE a<2 PRINT ''', [res1, res2]) # SQL union using pandas fsql(''' SELECT * FROM x UNION SELECT * FROM y SELECT * WHERE a<2 PRINT ''', [res1, res2], engine=\"duckdb\") # SQL union using duckdb (if installed) # Pass in other parameters and dataframes @task def gen_df(): return pd.DataFrame(dict(a=[1])) @task def gen_path(): return \"/tmp/t.parquet\" @flow def flow2() df = gen_df() path = gen_path() fsql(''' SELECT a+1 AS a FROM df SAVE OVERWRITE {{path}} ''', df=df, path=path) # Disable checkpoint for distributed dataframes from pyspark.sql import SparkSession spark = SparkSession.builder.getOrCreate() @flow def flow3() with fugue_engine(spark, checkpoint=False): # res1 needs to turn off checkpoint because it yields # a Spark DataFrame res1 = fsql(''' CREATE [[1],[2]] SCHEMA a:int YIELD DATAFRAME AS y ''') # res2 doesn't need to turn off checkpoint because it yields # a local DataFrame (most likely Pandas DataFrame) res2 = fsql(''' CREATE [[1],[2]] SCHEMA a:int YIELD LOCAL DATAFRAME AS y ''', checkpoint=True) # res3 doesn't need to turn off checkpoint because it yields # a file (the dataframe is cached in the file) res3 = fsql(''' CREATE [[-1],[3]] SCHEMA a:int YIELD FILE AS z ''', checkpoint=True) # this step doesn't need to turn off checkpoint because it # doesn't have any output fsql(''' SELECT * FROM x UNION SELECT * FROM y UNION SELECT * FROM z SELECT * WHERE a<2 PRINT ''', [res1, res2, res3]) ``` Note: The best practice is always yielding files or local dataframes. If you want to yield a distributed dataframe such as Spark or Dask, think it twice. `YIELD FILE` is always preferred when Fugue SQL is running as a Prefect task. If you feel `YIELD FILE` is too heavy, that means your SQL logic may not be heavy enough to be broken into multiple tasks. \"\"\" tn = _truncate_name ( query ) if engine is None and engine_conf is None : engine = current_fugue_engine () elif checkpoint is None : checkpoint = False global_vars , local_vars = get_caller_global_local_vars () @task ( name = tn + suffix (), description = query , cache_key_fn = _get_cache_key_fn ( checkpoint ), ) def run_fsql ( query : str , yields : Any , engine : Any = None , engine_conf : Any = None , ) -> dict : logger = get_run_logger () logger . debug ( query ) dag = fugue_sql . FugueSQLWorkflow ( None , { FUGUE_CONF_SQL_IGNORE_CASE : fsql_ignore_case } ) try : dag . _sql ( query , global_vars , local_vars , * _normalize_yields ( yields ), ** kwargs ) except SyntaxError as ex : raise SyntaxError ( str ( ex )) . with_traceback ( None ) from None dag . run ( engine , engine_conf ) result : Dict [ str , Any ] = {} for k , v in dag . yields . items (): if isinstance ( v , fugue . dataframe . YieldedDataFrame ): result [ k ] = v . result # type: ignore else : result [ k ] = v # type: ignore return result return run_fsql ( query = query , yields = yields , engine = engine , engine_conf = engine_conf ) transform Function for running Fugue transform function. This function generates the Prefect task that runs Fugue transform. Parameters: Name Type Description Default - df (Any a dataframe or a file path generated from the previous steps required - transformer (Any a function or class that be recognized by Fugue as a transformer required - engine (Any execution engine expression that can be recognized by Fugue, default to None (the default ExecutionEngine of Fugue) required - engine_conf (Any extra execution engine configs, defaults to None required - checkpoint (bool whether to checkpoint this task in Prefect, defaults to None (determined by the fugue_engine context). required - **kwargs (Any additional kwargs to pass to Fugue's transform function required References See: Fugue Transform Example from prefect import flow , task from prefect.tasks.fugue import transform , fsql , fugue_engine from dask.distributed import Client import pandas as pd client = Client ( processes = True ) # Basic usage @task def gen_df () -> pd . DataFrame : return pd . DataFrame ( dict ( a = [ 1 ])) @task def show_df ( dask_df ): print ( dask_df . compute ()) def add_col ( df : pd . DataFrame ) -> pd . DataFrame return df . assign ( b = 2 ) @flow def flow1 (): df = gen_df () dask_df = transform ( df , add_col , schema = \"*,b:int\" , engine = client ) show_df ( dask_df ) # Turning on checkpoint when returning a local dataframe @flow def flow2 (): df = gen_df () local_df = transform ( df , add_col , schema = \"*,b:int\" , engine = client , as_local = True , checkpoint = True ) # fsql + transform @flow def flow3 (): with fugue_engine ( client , checkpoint = False ): dfs = fsql ( \"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\" ) dask_df = transform ( dfs [ \"x\" ], add_col , schema = \"*,b:int\" ) fsql ( ''' SELECT * FROM df WHERE b<3 PRINT ''' , df = dask_df ) Source code in prefect_fugue/tasks.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 def transform ( df : Any , transformer : Any , engine : Any = None , engine_conf : Any = None , checkpoint : Optional [ bool ] = None , ** kwargs ) -> Any : \"\"\" Function for running Fugue transform function. This function generates the Prefect task that runs Fugue transform. Args: - df (Any): a dataframe or a file path generated from the previous steps - transformer (Any): a function or class that be recognized by Fugue as a transformer - engine (Any): execution engine expression that can be recognized by Fugue, default to None (the default ExecutionEngine of Fugue) - engine_conf (Any): extra execution engine configs, defaults to None - checkpoint (bool, optional): whether to checkpoint this task in Prefect, defaults to None (determined by the ``fugue_engine`` context). - **kwargs (Any, optional): additional kwargs to pass to Fugue's `transform` function References: - See: [Fugue Transform](https://fugue-tutorials.readthedocs.io/tutorials/extensions/transformer.html) Example: ```python from prefect import flow, task from prefect.tasks.fugue import transform, fsql, fugue_engine from dask.distributed import Client import pandas as pd client = Client(processes=True) # Basic usage @task def gen_df() -> pd.DataFrame: return pd.DataFrame(dict(a=[1])) @task def show_df(dask_df): print(dask_df.compute()) def add_col(df:pd.DataFrame) -> pd.DataFrame return df.assign(b=2) @flow def flow1(): df = gen_df() dask_df = transform(df, add_col, schema=\"*,b:int\", engine=client) show_df(dask_df) # Turning on checkpoint when returning a local dataframe @flow def flow2(): df = gen_df() local_df = transform(df, add_col, schema=\"*,b:int\", engine=client, as_local=True, checkpoint=True) # fsql + transform @flow def flow3(): with fugue_engine(client, checkpoint=False): dfs = fsql(\"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\") dask_df = transform(dfs[\"x\"], add_col, schema=\"*,b:int\") fsql(''' SELECT * FROM df WHERE b<3 PRINT ''', df=dask_df) ``` \"\"\" tn = transformer . __name__ + \" (transfomer)\" if engine is None and engine_conf is None : engine = current_fugue_engine () elif checkpoint is None : checkpoint = False _t = _to_transformer ( transformer , kwargs . get ( \"schema\" , None )) @task ( name = tn + suffix (), cache_key_fn = _get_cache_key_fn ( checkpoint )) def _run_with_func ( df : Any , ** kwargs ): kw = dict ( kwargs ) kw . pop ( \"schema\" , None ) return fugue . transform ( df , _t , ** kw ) return _run_with_func ( df , engine = engine , engine_conf = engine_conf , ** kwargs )","title":"Tasks"},{"location":"tasks/#prefect_fugue.tasks","text":"","title":"tasks"},{"location":"tasks/#prefect_fugue.tasks.fsql","text":"Function for running Fugue SQL. This function generates the Prefect task that runs Fugue SQL. Parameters: Name Type Description Default - query (str the Fugue SQL query required - yields (Any the yielded dataframes from the previous tasks, defaults to None. It can be a single yielded result or an array of yielded results (see example) required - engine (Any execution engine expression that can be recognized by Fugue, default to None (the default ExecutionEngine of Fugue) required - engine_conf (Any extra execution engine configs, defaults to None required - checkpoint (bool whether to checkpoint this task in Prefect, defaults to None (determined by the fugue_engine context). required - **kwargs (Any additional kwargs to pass to Fugue's fsql function required References See: Fugue SQL Tutorial Example from prefect import flow , task from prefect.tasks.fugue import fsql , fugue_engine import pandas as pd # Basic usage @flow def flow1 () res1 = fsql ( \"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\" ) res2 = fsql ( \"CREATE [[1],[2]] SCHEMA a:int YIELD DATAFRAME AS y\" ) fsql ( ''' SELECT * FROM x UNION SELECT * FROM y SELECT * WHERE a<2 PRINT ''' , [ res1 , res2 ]) # SQL union using pandas fsql ( ''' SELECT * FROM x UNION SELECT * FROM y SELECT * WHERE a<2 PRINT ''' , [ res1 , res2 ], engine = \"duckdb\" ) # SQL union using duckdb (if installed) # Pass in other parameters and dataframes @task def gen_df (): return pd . DataFrame ( dict ( a = [ 1 ])) @task def gen_path (): return \"/tmp/t.parquet\" @flow def flow2 () df = gen_df () path = gen_path () fsql ( ''' SELECT a+1 AS a FROM df SAVE OVERWRITE {{path}} ''' , df = df , path = path ) # Disable checkpoint for distributed dataframes from pyspark.sql import SparkSession spark = SparkSession . builder . getOrCreate () @flow def flow3 () with fugue_engine ( spark , checkpoint = False ): # res1 needs to turn off checkpoint because it yields # a Spark DataFrame res1 = fsql ( ''' CREATE [[1],[2]] SCHEMA a:int YIELD DATAFRAME AS y ''' ) # res2 doesn't need to turn off checkpoint because it yields # a local DataFrame (most likely Pandas DataFrame) res2 = fsql ( ''' CREATE [[1],[2]] SCHEMA a:int YIELD LOCAL DATAFRAME AS y ''' , checkpoint = True ) # res3 doesn't need to turn off checkpoint because it yields # a file (the dataframe is cached in the file) res3 = fsql ( ''' CREATE [[-1],[3]] SCHEMA a:int YIELD FILE AS z ''' , checkpoint = True ) # this step doesn't need to turn off checkpoint because it # doesn't have any output fsql ( ''' SELECT * FROM x UNION SELECT * FROM y UNION SELECT * FROM z SELECT * WHERE a<2 PRINT ''' , [ res1 , res2 , res3 ]) you want to yield a distributed dataframe such as Spark or Dask, think it twice. YIELD FILE is always preferred when Fugue SQL is running as a Prefect task. If you feel YIELD FILE is too heavy, that means your SQL logic may not be heavy enough to be broken into multiple tasks. Source code in prefect_fugue/tasks.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def fsql ( query : str , yields : Any = None , engine : Any = None , engine_conf : Any = None , checkpoint : Optional [ bool ] = None , fsql_ignore_case : bool = False , ** kwargs : Any ) -> dict : \"\"\" Function for running Fugue SQL. This function generates the Prefect task that runs Fugue SQL. Args: - query (str): the Fugue SQL query - yields (Any): the yielded dataframes from the previous tasks, defaults to None. It can be a single yielded result or an array of yielded results (see example) - engine (Any): execution engine expression that can be recognized by Fugue, default to None (the default ExecutionEngine of Fugue) - engine_conf (Any): extra execution engine configs, defaults to None - checkpoint (bool, optional): whether to checkpoint this task in Prefect, defaults to None (determined by the ``fugue_engine`` context). - **kwargs (Any, optional): additional kwargs to pass to Fugue's `fsql` function References: - See: [Fugue SQL Tutorial](https://fugue-tutorials.readthedocs.io/tutorials/fugue_sql/index.html) Example: ```python from prefect import flow, task from prefect.tasks.fugue import fsql, fugue_engine import pandas as pd # Basic usage @flow def flow1() res1 = fsql(\"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\") res2 = fsql(\"CREATE [[1],[2]] SCHEMA a:int YIELD DATAFRAME AS y\") fsql(''' SELECT * FROM x UNION SELECT * FROM y SELECT * WHERE a<2 PRINT ''', [res1, res2]) # SQL union using pandas fsql(''' SELECT * FROM x UNION SELECT * FROM y SELECT * WHERE a<2 PRINT ''', [res1, res2], engine=\"duckdb\") # SQL union using duckdb (if installed) # Pass in other parameters and dataframes @task def gen_df(): return pd.DataFrame(dict(a=[1])) @task def gen_path(): return \"/tmp/t.parquet\" @flow def flow2() df = gen_df() path = gen_path() fsql(''' SELECT a+1 AS a FROM df SAVE OVERWRITE {{path}} ''', df=df, path=path) # Disable checkpoint for distributed dataframes from pyspark.sql import SparkSession spark = SparkSession.builder.getOrCreate() @flow def flow3() with fugue_engine(spark, checkpoint=False): # res1 needs to turn off checkpoint because it yields # a Spark DataFrame res1 = fsql(''' CREATE [[1],[2]] SCHEMA a:int YIELD DATAFRAME AS y ''') # res2 doesn't need to turn off checkpoint because it yields # a local DataFrame (most likely Pandas DataFrame) res2 = fsql(''' CREATE [[1],[2]] SCHEMA a:int YIELD LOCAL DATAFRAME AS y ''', checkpoint=True) # res3 doesn't need to turn off checkpoint because it yields # a file (the dataframe is cached in the file) res3 = fsql(''' CREATE [[-1],[3]] SCHEMA a:int YIELD FILE AS z ''', checkpoint=True) # this step doesn't need to turn off checkpoint because it # doesn't have any output fsql(''' SELECT * FROM x UNION SELECT * FROM y UNION SELECT * FROM z SELECT * WHERE a<2 PRINT ''', [res1, res2, res3]) ``` Note: The best practice is always yielding files or local dataframes. If you want to yield a distributed dataframe such as Spark or Dask, think it twice. `YIELD FILE` is always preferred when Fugue SQL is running as a Prefect task. If you feel `YIELD FILE` is too heavy, that means your SQL logic may not be heavy enough to be broken into multiple tasks. \"\"\" tn = _truncate_name ( query ) if engine is None and engine_conf is None : engine = current_fugue_engine () elif checkpoint is None : checkpoint = False global_vars , local_vars = get_caller_global_local_vars () @task ( name = tn + suffix (), description = query , cache_key_fn = _get_cache_key_fn ( checkpoint ), ) def run_fsql ( query : str , yields : Any , engine : Any = None , engine_conf : Any = None , ) -> dict : logger = get_run_logger () logger . debug ( query ) dag = fugue_sql . FugueSQLWorkflow ( None , { FUGUE_CONF_SQL_IGNORE_CASE : fsql_ignore_case } ) try : dag . _sql ( query , global_vars , local_vars , * _normalize_yields ( yields ), ** kwargs ) except SyntaxError as ex : raise SyntaxError ( str ( ex )) . with_traceback ( None ) from None dag . run ( engine , engine_conf ) result : Dict [ str , Any ] = {} for k , v in dag . yields . items (): if isinstance ( v , fugue . dataframe . YieldedDataFrame ): result [ k ] = v . result # type: ignore else : result [ k ] = v # type: ignore return result return run_fsql ( query = query , yields = yields , engine = engine , engine_conf = engine_conf )","title":"fsql()"},{"location":"tasks/#prefect_fugue.tasks.transform","text":"Function for running Fugue transform function. This function generates the Prefect task that runs Fugue transform. Parameters: Name Type Description Default - df (Any a dataframe or a file path generated from the previous steps required - transformer (Any a function or class that be recognized by Fugue as a transformer required - engine (Any execution engine expression that can be recognized by Fugue, default to None (the default ExecutionEngine of Fugue) required - engine_conf (Any extra execution engine configs, defaults to None required - checkpoint (bool whether to checkpoint this task in Prefect, defaults to None (determined by the fugue_engine context). required - **kwargs (Any additional kwargs to pass to Fugue's transform function required References See: Fugue Transform Example from prefect import flow , task from prefect.tasks.fugue import transform , fsql , fugue_engine from dask.distributed import Client import pandas as pd client = Client ( processes = True ) # Basic usage @task def gen_df () -> pd . DataFrame : return pd . DataFrame ( dict ( a = [ 1 ])) @task def show_df ( dask_df ): print ( dask_df . compute ()) def add_col ( df : pd . DataFrame ) -> pd . DataFrame return df . assign ( b = 2 ) @flow def flow1 (): df = gen_df () dask_df = transform ( df , add_col , schema = \"*,b:int\" , engine = client ) show_df ( dask_df ) # Turning on checkpoint when returning a local dataframe @flow def flow2 (): df = gen_df () local_df = transform ( df , add_col , schema = \"*,b:int\" , engine = client , as_local = True , checkpoint = True ) # fsql + transform @flow def flow3 (): with fugue_engine ( client , checkpoint = False ): dfs = fsql ( \"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\" ) dask_df = transform ( dfs [ \"x\" ], add_col , schema = \"*,b:int\" ) fsql ( ''' SELECT * FROM df WHERE b<3 PRINT ''' , df = dask_df ) Source code in prefect_fugue/tasks.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 def transform ( df : Any , transformer : Any , engine : Any = None , engine_conf : Any = None , checkpoint : Optional [ bool ] = None , ** kwargs ) -> Any : \"\"\" Function for running Fugue transform function. This function generates the Prefect task that runs Fugue transform. Args: - df (Any): a dataframe or a file path generated from the previous steps - transformer (Any): a function or class that be recognized by Fugue as a transformer - engine (Any): execution engine expression that can be recognized by Fugue, default to None (the default ExecutionEngine of Fugue) - engine_conf (Any): extra execution engine configs, defaults to None - checkpoint (bool, optional): whether to checkpoint this task in Prefect, defaults to None (determined by the ``fugue_engine`` context). - **kwargs (Any, optional): additional kwargs to pass to Fugue's `transform` function References: - See: [Fugue Transform](https://fugue-tutorials.readthedocs.io/tutorials/extensions/transformer.html) Example: ```python from prefect import flow, task from prefect.tasks.fugue import transform, fsql, fugue_engine from dask.distributed import Client import pandas as pd client = Client(processes=True) # Basic usage @task def gen_df() -> pd.DataFrame: return pd.DataFrame(dict(a=[1])) @task def show_df(dask_df): print(dask_df.compute()) def add_col(df:pd.DataFrame) -> pd.DataFrame return df.assign(b=2) @flow def flow1(): df = gen_df() dask_df = transform(df, add_col, schema=\"*,b:int\", engine=client) show_df(dask_df) # Turning on checkpoint when returning a local dataframe @flow def flow2(): df = gen_df() local_df = transform(df, add_col, schema=\"*,b:int\", engine=client, as_local=True, checkpoint=True) # fsql + transform @flow def flow3(): with fugue_engine(client, checkpoint=False): dfs = fsql(\"CREATE [[0]] SCHEMA a:int YIELD DATAFRAME AS x\") dask_df = transform(dfs[\"x\"], add_col, schema=\"*,b:int\") fsql(''' SELECT * FROM df WHERE b<3 PRINT ''', df=dask_df) ``` \"\"\" tn = transformer . __name__ + \" (transfomer)\" if engine is None and engine_conf is None : engine = current_fugue_engine () elif checkpoint is None : checkpoint = False _t = _to_transformer ( transformer , kwargs . get ( \"schema\" , None )) @task ( name = tn + suffix (), cache_key_fn = _get_cache_key_fn ( checkpoint )) def _run_with_func ( df : Any , ** kwargs ): kw = dict ( kwargs ) kw . pop ( \"schema\" , None ) return fugue . transform ( df , _t , ** kw ) return _run_with_func ( df , engine = engine , engine_conf = engine_conf , ** kwargs )","title":"transform()"}]}